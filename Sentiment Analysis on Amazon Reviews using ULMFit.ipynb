{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Ayush9719/Fellowship-Ai/blob/main/Sentiment%20Analysis%20on%20Amazon%20Reviews%20using%20ULMFit.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "meAaNlt3xm3h",
        "outputId": "f84e543f-89c4-449b-a1e5-52c507288fba"
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "import torch\n",
        "import fastai\n",
        "from fastai.text import *\n",
        "fastai.__version__"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'1.0.61'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rVN6Wa4IxpyN"
      },
      "source": [
        "path = untar_data(URLs.AMAZON_REVIEWS, dest = \"Data\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jP3op_4nx_Ie",
        "outputId": "a471ea3c-ea2d-4677-fdf1-a1156fc30e8c"
      },
      "source": [
        "path.ls()"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('Data/amazon_review_full_csv/lm_databunch-amazon'),\n",
              " PosixPath('Data/amazon_review_full_csv/models'),\n",
              " PosixPath('Data/amazon_review_full_csv/test.csv'),\n",
              " PosixPath('Data/amazon_review_full_csv/readme.txt'),\n",
              " PosixPath('Data/amazon_review_full_csv/train.csv')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "5dQv9QLeyJ4r",
        "outputId": "0b69e13f-9b29-4bde-e3d9-a43e5b03744b"
      },
      "source": [
        "train_df = pd.read_csv(path/'train.csv', header=None, names=['Rating', 'Title', 'Review'], skiprows=(2000000))\n",
        "train_df.head()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>Interesting form.</td>\n",
              "      <td>Interesting kung fu style-- Combination of Whi...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4</td>\n",
              "      <td>Excellent advice on cutting fat &amp; increasing f...</td>\n",
              "      <td>This is a well organized book with lots of use...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>5</td>\n",
              "      <td>Wise, practical, and medically sound</td>\n",
              "      <td>Life is about making choices and owning up to ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1</td>\n",
              "      <td>Starve your kids now so they can be fat later.</td>\n",
              "      <td>Another book that teaches kids that being bigg...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>If John Sayles adapted a Joseph Wambaugh story...</td>\n",
              "      <td>Evenhand is a very impressive accomplishment: ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating  ...                                             Review\n",
              "0       3  ...  Interesting kung fu style-- Combination of Whi...\n",
              "1       4  ...  This is a well organized book with lots of use...\n",
              "2       5  ...  Life is about making choices and owning up to ...\n",
              "3       1  ...  Another book that teaches kids that being bigg...\n",
              "4       3  ...  Evenhand is a very impressive accomplishment: ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "31vaZIPYyW9R",
        "outputId": "a703d805-89b1-4881-fc97-4a393e6f4008"
      },
      "source": [
        "valid_df = pd.read_csv(path/'test.csv', header=None, names=['Rating', 'Title', 'Review'], skiprows=(435000))\n",
        "valid_df.head()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Rating</th>\n",
              "      <th>Title</th>\n",
              "      <th>Review</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>3</td>\n",
              "      <td>product quality good but ivory color not</td>\n",
              "      <td>I ordered the ivory color of these plates as I...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>5</td>\n",
              "      <td>made in america</td>\n",
              "      <td>I currently own six of these sets in different...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>Fiesta Dishes</td>\n",
              "      <td>I have several place settings of Fiesta Dishes...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>Place setting</td>\n",
              "      <td>I read the title wrong. I thought I was gettin...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>5</td>\n",
              "      <td>Excellent reference</td>\n",
              "      <td>This book is for any mother in the process of ...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   Rating  ...                                             Review\n",
              "0       3  ...  I ordered the ivory color of these plates as I...\n",
              "1       5  ...  I currently own six of these sets in different...\n",
              "2       2  ...  I have several place settings of Fiesta Dishes...\n",
              "3       2  ...  I read the title wrong. I thought I was gettin...\n",
              "4       5  ...  This book is for any mother in the process of ...\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_AGdJ6tbFePt"
      },
      "source": [
        "**The Language Model Data Object**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "x7jEfY0VAArQ",
        "outputId": "6408bd2d-75c8-41c8-f6fe-0737ab0718de"
      },
      "source": [
        "data_lm = TextLMDataBunch.from_df(path=path, train_df=train_df[:1000], valid_df=valid_df[:1000], text_cols=2, label_cols=0)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qZ-bVPqflhNA"
      },
      "source": [
        "data_lm.save('lm_databunch-amazon')"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CCRrhXIiFxFl"
      },
      "source": [
        "**Training the Language Mode**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WWN1PA8Glki4"
      },
      "source": [
        "learn = language_model_learner(data_lm, drop_mult=0.3, arch=AWD_LSTM)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hLTr3IRqF_hD"
      },
      "source": [
        "**Finding a Learning Rate**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        },
        "id": "6A5FYDP9lykv",
        "outputId": "1a79a77e-59ea-4e86-a9c2-9ebee68c5d25"
      },
      "source": [
        "learn.lr_find(start_lr = slice(10e-7, 10e-5), end_lr=slice(0.1, 10))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='4' class='' max='5' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      80.00% [4/5 06:49<01:42]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.454299</td>\n",
              "      <td>#na#</td>\n",
              "      <td>01:43</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>4.321419</td>\n",
              "      <td>#na#</td>\n",
              "      <td>01:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>4.065765</td>\n",
              "      <td>#na#</td>\n",
              "      <td>01:42</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>4.904997</td>\n",
              "      <td>#na#</td>\n",
              "      <td>01:42</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='15' class='' max='21' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      71.43% [15/21 02:45<01:06 14.4232]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "RVVxbwpel4gR",
        "outputId": "53f94f86-0ca4-43cb-e405-43019b46d12c"
      },
      "source": [
        "learn.recorder.plot(skip_end=10, suggestion=True)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min numerical gradient: 1.58E-01\n",
            "Min loss divided by 10: 2.51E-02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tV1Pbwka29Vl"
      },
      "source": [
        "best_lm_lr = 1E-02"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1lHQmDpqGKjQ"
      },
      "source": [
        "**Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 114
        },
        "id": "T3lZFd_T3It0",
        "outputId": "e35b8a95-f893-45e2-97c9-ee7cf953f04a"
      },
      "source": [
        "%%time\n",
        "learn.fit_one_cycle(1, best_lm_lr)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>4.289950</td>\n",
              "      <td>3.798102</td>\n",
              "      <td>0.282175</td>\n",
              "      <td>02:36</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 2min 36s, sys: 1.01 s, total: 2min 37s\n",
            "Wall time: 2min 36s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DiYL9HkA8B2"
      },
      "source": [
        "learn.save('lm-fit_1')"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsltxTUyA9L0",
        "outputId": "8acf6d1d-1cf0-42ed-d958-03eb33c898dd"
      },
      "source": [
        "learn.load('lm-fit_1')"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "LanguageLearner(data=TextLMDataBunch;\n",
              "\n",
              "Train: LabelList (1000 items)\n",
              "x: LMTextList\n",
              "xxbos xxmaj interesting kung fu xxunk xxmaj combination of xxmaj white xxmaj xxunk and xxmaj xxunk xxmaj xxunk ? xxmaj the practitioners seem to have solid xxunk and not a lot of superfluous or wasted movement . xxmaj would like to have seen more applications xxunk just a couple in the last few minutes of the video , basically an arm lock and a push . xxmaj thanks to xxmaj amazon for making these available to rent ! xxmaj enjoyable for esoteric xxunk arts video junkies like myself , gives you a chance to see what other styles you 're not likely to find at the local xxunk xxunk are doing , and to \" try before you buy \" . i 've bought several videos from the same company as this one on sale cheap , some are excellent , some are lousy , this one is in the middle . xxmaj not recommended for people wanting to learn self defense because a ) self defense applications are not xxunk out clearly , and b ) even if they were , a live teacher and a lot of realistic training is needed to make any system work in real life .,xxbos xxmaj this is a well organized book with lots of useful advice and good xxunk xxunk . i just have two complaints : 1 ) xxmaj there is an xxunk that heavy kids are heavy because they eat junk food and do n't exercise . i 'm living with a heavy kid who rarely xxunk junk food and has always xxunk a lot . xxmaj this message is frustrating , to say the least . 2 ) xxmaj the title is a problem . xxmaj my daughter is already xxunk - sensitive about her weight , were i to buy this book ( i read it at the library ) , the title itself would confirm to her that i find her \" fat . \" xxmaj in fact , i would purchase this book , were it not for the title because it is among the best of the books covering the subject , and i 've read a number of them . i appreciate the books emphasis on physical xxunk . i think a person who is xxunk fit has a better life and feels better in every way . xxmaj parents have an xxunk to xxunk such well being as far as i 'm concerned .,xxbos xxmaj life is about making choices and xxunk up to them . xxmaj too many kids in xxmaj america are fat . xxmaj this did n't used to be so . xxmaj times have changed . xxmaj here is advise on xxunk yourself and your kids . xxmaj setting a good example , teaching them how to make proper choices , and xxunk them for a healthy life . xxmaj does n't neglect exercise . xxmaj good recipes . xxmaj does n't require xxunk fat or xxunk , just being smart . xxmaj put away your xxunk and become a xxunk in your household , here 's how . xxmaj your kids and xxunk will thank you for generations .,xxbos xxmaj another book that teaches kids that being bigger is a personal xxunk caused by personal xxunk , and too much eating . xxmaj if you just quit doing ' this ' and stop doing ' that ' you can be just like the other kids . xxmaj complete xxunk . a waste of money . xxmaj find a book that will teach your children about the value of being different , not one that tries to xxunk them into xxunk xxunk .,xxbos xxmaj xxunk is a very impressive xxunk : a quiet , xxunk cop film . xxmaj its premise is familiar : two very different xxunk working to xxunk to each other and to the many xxunk of their jobs as xxunk . xxmaj so it 's very much a character study , and the two xxunk actors -- xxmaj bill xxmaj sage and xxmaj bill xxmaj xxunk -- do an excellent job of xxunk their characters . xxmaj as the film 's energy is xxunk from their characters ' different xxunk , it would have been very easy for each of their performances to become xxunk . xxmaj they did not . xxmaj in each , you see a fully - xxunk person , including xxunk of his partner 's xxunk . xxmaj that 's good acting of good writing . i also enjoyed the matter - of - fact style of the film , which xxunk me of xxmaj xxunk xxmaj xxunk 's wonderful and under - appreciated xxmaj ruby xxmaj in xxmaj xxunk .\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: Data/amazon_review_full_csv;\n",
              "\n",
              "Valid: LabelList (1000 items)\n",
              "x: LMTextList\n",
              "xxbos i ordered the xxunk color of these xxunk as i wanted something neutral but not completely white . xxmaj the xxunk color is more of a xxunk color so i sent them back . xxmaj overall , i loved the dishes and the fact that they are made in the xxup usa and are lead - free . i will buy them again but find a color that works for me .,xxbos i currently own six of these sets in different colors . xxmaj these xxunk are heavy and well made . xxmaj worth the price . xxmaj my xxunk now looks like something out of a xxmaj xxunk xxmaj anderson movie .,xxbos i have several place settings of xxmaj xxunk xxmaj dishes . i ordered 2 more place settings recently and was dissapointed with them . xxmaj the dishes are warped and do n't stack well with my other dishes . xxmaj these dishes are xxunk xxunk . i love the idea of the xxmaj xxunk brand but these were not like my others .,xxbos i read the title wrong . i thought i was getting a setting for four . xxmaj one of the xxunk came xxunk and i made a note of it on here . i never got a response . i decided to keep it . i am not going to buy any more sets . i saw a few days ago at xxmaj xxunk , they have the same set . xxmaj it was xxunk cheaper with your xxmaj xxunk xxunk .,xxbos xxmaj this book is for any mother in the process of xxunk . xxmaj unlike one reviewer , i thought the author did an excellent job of explaining everything a mother needs to consider . xxmaj the tips were so helpful ... so many things i had n't thought of ! xxmaj it gave me insight into my children 's needs , and insight into xxunk , xxunk , and child support , xxunk an xxunk , etc . i believe i got a much better xxunk because of this book , and it gave me piece of mind to read the stories of the women it detailed . i bought several books to try to xxunk myself , but this one was the best by far . xxmaj it covers so many topics . xxmaj it should be recommended reading by xxunk , xxunk , and marriage xxunk .\n",
              "y: LMLabelList\n",
              ",,,,\n",
              "Path: Data/amazon_review_full_csv;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): AWD_LSTM(\n",
              "    (encoder): Embedding(3952, 400, padding_idx=1)\n",
              "    (encoder_dp): EmbeddingDropout(\n",
              "      (emb): Embedding(3952, 400, padding_idx=1)\n",
              "    )\n",
              "    (rnns): ModuleList(\n",
              "      (0): WeightDropout(\n",
              "        (module): LSTM(400, 1152, batch_first=True)\n",
              "      )\n",
              "      (1): WeightDropout(\n",
              "        (module): LSTM(1152, 1152, batch_first=True)\n",
              "      )\n",
              "      (2): WeightDropout(\n",
              "        (module): LSTM(1152, 400, batch_first=True)\n",
              "      )\n",
              "    )\n",
              "    (input_dp): RNNDropout()\n",
              "    (hidden_dps): ModuleList(\n",
              "      (0): RNNDropout()\n",
              "      (1): RNNDropout()\n",
              "      (2): RNNDropout()\n",
              "    )\n",
              "  )\n",
              "  (1): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=3952, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f3d7998fa70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('Data/amazon_review_full_csv'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: ...\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): Embedding(3952, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3952, 400, padding_idx=1)\n",
              "  )\n",
              "  (2): LinearDecoder(\n",
              "    (decoder): Linear(in_features=400, out_features=3952, bias=True)\n",
              "    (output_dp): RNNDropout()\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V7yFubJKHj_s"
      },
      "source": [
        "learn.unfreeze()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "xtZcFwA11bJB",
        "outputId": "eafd41d4-efcd-4599-c8e1-f9a69d16d3b8"
      },
      "source": [
        "%%time\n",
        "learn.fit_one_cycle(5, best_lm_lr)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>3.881527</td>\n",
              "      <td>3.736381</td>\n",
              "      <td>0.279177</td>\n",
              "      <td>03:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>3.581519</td>\n",
              "      <td>3.864694</td>\n",
              "      <td>0.268527</td>\n",
              "      <td>03:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>3.084628</td>\n",
              "      <td>4.035291</td>\n",
              "      <td>0.255091</td>\n",
              "      <td>03:49</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>2.456693</td>\n",
              "      <td>4.376310</td>\n",
              "      <td>0.238956</td>\n",
              "      <td>03:48</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.902664</td>\n",
              "      <td>4.491127</td>\n",
              "      <td>0.239520</td>\n",
              "      <td>03:48</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "CPU times: user 18min 57s, sys: 12.3 s, total: 19min 9s\n",
            "Wall time: 19min 4s\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7lshaeWh1dM9"
      },
      "source": [
        "learn.save('lm-fine_tuned')"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M6s2ZaudfJMV"
      },
      "source": [
        "learn.save_encoder('lm-fine_tuned_enc')"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MEMtQs3YGTnU"
      },
      "source": [
        "**Building a Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "id": "7ZmXpC1qfRpy",
        "outputId": "819a8d3f-2e39-4ee3-d83b-8d283bd3b91f"
      },
      "source": [
        "data_clas = TextClasDataBunch.from_df(path, train_df=train_df[:1000], valid_df=valid_df[:1000], text_cols=2, label_cols=0, vocab=data_lm.train_ds.vocab)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/fastai/core.py:302: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return np.array(a, dtype=dtype, **kwargs)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              ""
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X_oQCZ3mfeCu"
      },
      "source": [
        "data_clas.save('class-databunch-amazon')"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wuit-zIxfuwc"
      },
      "source": [
        "learn_c = text_classifier_learner(data_clas, AWD_LSTM, drop_mult=1)"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qMf_td5-f33q",
        "outputId": "5c81636d-67af-4f58-839f-666e84c11458"
      },
      "source": [
        "learn_c.load_encoder('lm-fine_tuned_enc')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (1000 items)\n",
              "x: TextList\n",
              "xxbos xxmaj interesting kung fu xxunk xxmaj combination of xxmaj white xxmaj xxunk and xxmaj xxunk xxmaj xxunk ? xxmaj the practitioners seem to have solid xxunk and not a lot of superfluous or wasted movement . xxmaj would like to have seen more applications xxunk just a couple in the last few minutes of the video , basically an arm lock and a push . xxmaj thanks to xxmaj amazon for making these available to rent ! xxmaj enjoyable for esoteric xxunk arts video junkies like myself , gives you a chance to see what other styles you 're not likely to find at the local xxunk xxunk are doing , and to \" try before you buy \" . i 've bought several videos from the same company as this one on sale cheap , some are excellent , some are lousy , this one is in the middle . xxmaj not recommended for people wanting to learn self defense because a ) self defense applications are not xxunk out clearly , and b ) even if they were , a live teacher and a lot of realistic training is needed to make any system work in real life .,xxbos xxmaj this is a well organized book with lots of useful advice and good xxunk xxunk . i just have two complaints : 1 ) xxmaj there is an xxunk that heavy kids are heavy because they eat junk food and do n't exercise . i 'm living with a heavy kid who rarely xxunk junk food and has always xxunk a lot . xxmaj this message is frustrating , to say the least . 2 ) xxmaj the title is a problem . xxmaj my daughter is already xxunk - sensitive about her weight , were i to buy this book ( i read it at the library ) , the title itself would confirm to her that i find her \" fat . \" xxmaj in fact , i would purchase this book , were it not for the title because it is among the best of the books covering the subject , and i 've read a number of them . i appreciate the books emphasis on physical xxunk . i think a person who is xxunk fit has a better life and feels better in every way . xxmaj parents have an xxunk to xxunk such well being as far as i 'm concerned .,xxbos xxmaj life is about making choices and xxunk up to them . xxmaj too many kids in xxmaj america are fat . xxmaj this did n't used to be so . xxmaj times have changed . xxmaj here is advise on xxunk yourself and your kids . xxmaj setting a good example , teaching them how to make proper choices , and xxunk them for a healthy life . xxmaj does n't neglect exercise . xxmaj good recipes . xxmaj does n't require xxunk fat or xxunk , just being smart . xxmaj put away your xxunk and become a xxunk in your household , here 's how . xxmaj your kids and xxunk will thank you for generations .,xxbos xxmaj another book that teaches kids that being bigger is a personal xxunk caused by personal xxunk , and too much eating . xxmaj if you just quit doing ' this ' and stop doing ' that ' you can be just like the other kids . xxmaj complete xxunk . a waste of money . xxmaj find a book that will teach your children about the value of being different , not one that tries to xxunk them into xxunk xxunk .,xxbos xxmaj xxunk is a very impressive xxunk : a quiet , xxunk cop film . xxmaj its premise is familiar : two very different xxunk working to xxunk to each other and to the many xxunk of their jobs as xxunk . xxmaj so it 's very much a character study , and the two xxunk actors -- xxmaj bill xxmaj sage and xxmaj bill xxmaj xxunk -- do an excellent job of xxunk their characters . xxmaj as the film 's energy is xxunk from their characters ' different xxunk , it would have been very easy for each of their performances to become xxunk . xxmaj they did not . xxmaj in each , you see a fully - xxunk person , including xxunk of his partner 's xxunk . xxmaj that 's good acting of good writing . i also enjoyed the matter - of - fact style of the film , which xxunk me of xxmaj xxunk xxmaj xxunk 's wonderful and under - appreciated xxmaj ruby xxmaj in xxmaj xxunk .\n",
              "y: CategoryList\n",
              "3,4,5,1,3\n",
              "Path: Data/amazon_review_full_csv;\n",
              "\n",
              "Valid: LabelList (1000 items)\n",
              "x: TextList\n",
              "xxbos i ordered the xxunk color of these xxunk as i wanted something neutral but not completely white . xxmaj the xxunk color is more of a xxunk color so i sent them back . xxmaj overall , i loved the dishes and the fact that they are made in the xxup usa and are lead - free . i will buy them again but find a color that works for me .,xxbos i currently own six of these sets in different colors . xxmaj these xxunk are heavy and well made . xxmaj worth the price . xxmaj my xxunk now looks like something out of a xxmaj xxunk xxmaj anderson movie .,xxbos i have several place settings of xxmaj xxunk xxmaj dishes . i ordered 2 more place settings recently and was dissapointed with them . xxmaj the dishes are warped and do n't stack well with my other dishes . xxmaj these dishes are xxunk xxunk . i love the idea of the xxmaj xxunk brand but these were not like my others .,xxbos i read the title wrong . i thought i was getting a setting for four . xxmaj one of the xxunk came xxunk and i made a note of it on here . i never got a response . i decided to keep it . i am not going to buy any more sets . i saw a few days ago at xxmaj xxunk , they have the same set . xxmaj it was xxunk cheaper with your xxmaj xxunk xxunk .,xxbos xxmaj this book is for any mother in the process of xxunk . xxmaj unlike one reviewer , i thought the author did an excellent job of explaining everything a mother needs to consider . xxmaj the tips were so helpful ... so many things i had n't thought of ! xxmaj it gave me insight into my children 's needs , and insight into xxunk , xxunk , and child support , xxunk an xxunk , etc . i believe i got a much better xxunk because of this book , and it gave me piece of mind to read the stories of the women it detailed . i bought several books to try to xxunk myself , but this one was the best by far . xxmaj it covers so many topics . xxmaj it should be recommended reading by xxunk , xxunk , and marriage xxunk .\n",
              "y: CategoryList\n",
              "3,5,2,2,5\n",
              "Path: Data/amazon_review_full_csv;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3952, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3952, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.4, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f3d7998fa70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('Data/amazon_review_full_csv'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: ...\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(3952, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3952, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.4, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vzH8vmZeGcBE"
      },
      "source": [
        "**Training the Sentiment Classifier**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "id": "tST0nTXDf6DN",
        "outputId": "4e8090ef-ace4-42ac-b0c6-c323c1843a51"
      },
      "source": [
        "learn_c.lr_find()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='6' class='' max='7' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      85.71% [6/7 06:07<01:01]\n",
              "    </div>\n",
              "    \n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.756663</td>\n",
              "      <td>#na#</td>\n",
              "      <td>01:04</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.766005</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:58</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.745246</td>\n",
              "      <td>#na#</td>\n",
              "      <td>01:06</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.679974</td>\n",
              "      <td>#na#</td>\n",
              "      <td>01:01</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.603944</td>\n",
              "      <td>#na#</td>\n",
              "      <td>01:00</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>1.704882</td>\n",
              "      <td>#na#</td>\n",
              "      <td>00:56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>\n",
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "            .progress-bar-interrupted, .progress-bar-interrupted::-webkit-progress-bar {\n",
              "                background: #F44336;\n",
              "            }\n",
              "        </style>\n",
              "      <progress value='5' class='' max='15' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      33.33% [5/15 00:29<00:58 4.8140]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LR Finder is complete, type {learner_name}.recorder.plot() to see the graph.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 313
        },
        "id": "9Nbmkq3Lf96A",
        "outputId": "3a71cc99-e6d9-4097-c4f2-7e8217fb0686"
      },
      "source": [
        "learn_c.recorder.plot(suggestion=True)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Min numerical gradient: 2.51E-03\n",
            "Min loss divided by 10: 3.02E-02\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "id": "lN8ykZllliZu",
        "outputId": "39cca352-ae31-438e-9bee-4d902344737c"
      },
      "source": [
        "learn_c.fit_one_cycle(2, 1e-2)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.585029</td>\n",
              "      <td>1.506671</td>\n",
              "      <td>0.319000</td>\n",
              "      <td>02:02</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.475064</td>\n",
              "      <td>1.502566</td>\n",
              "      <td>0.342000</td>\n",
              "      <td>01:56</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i50DRZdnl8Lf"
      },
      "source": [
        "learn_c.save('class-first')"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GL-Ljkfzzg4c",
        "outputId": "5731081b-dc0c-4a22-e680-5e786b74f93d"
      },
      "source": [
        "learn_c.load('class-first')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (1000 items)\n",
              "x: TextList\n",
              "xxbos xxmaj interesting kung fu xxunk xxmaj combination of xxmaj white xxmaj xxunk and xxmaj xxunk xxmaj xxunk ? xxmaj the practitioners seem to have solid xxunk and not a lot of superfluous or wasted movement . xxmaj would like to have seen more applications xxunk just a couple in the last few minutes of the video , basically an arm lock and a push . xxmaj thanks to xxmaj amazon for making these available to rent ! xxmaj enjoyable for esoteric xxunk arts video junkies like myself , gives you a chance to see what other styles you 're not likely to find at the local xxunk xxunk are doing , and to \" try before you buy \" . i 've bought several videos from the same company as this one on sale cheap , some are excellent , some are lousy , this one is in the middle . xxmaj not recommended for people wanting to learn self defense because a ) self defense applications are not xxunk out clearly , and b ) even if they were , a live teacher and a lot of realistic training is needed to make any system work in real life .,xxbos xxmaj this is a well organized book with lots of useful advice and good xxunk xxunk . i just have two complaints : 1 ) xxmaj there is an xxunk that heavy kids are heavy because they eat junk food and do n't exercise . i 'm living with a heavy kid who rarely xxunk junk food and has always xxunk a lot . xxmaj this message is frustrating , to say the least . 2 ) xxmaj the title is a problem . xxmaj my daughter is already xxunk - sensitive about her weight , were i to buy this book ( i read it at the library ) , the title itself would confirm to her that i find her \" fat . \" xxmaj in fact , i would purchase this book , were it not for the title because it is among the best of the books covering the subject , and i 've read a number of them . i appreciate the books emphasis on physical xxunk . i think a person who is xxunk fit has a better life and feels better in every way . xxmaj parents have an xxunk to xxunk such well being as far as i 'm concerned .,xxbos xxmaj life is about making choices and xxunk up to them . xxmaj too many kids in xxmaj america are fat . xxmaj this did n't used to be so . xxmaj times have changed . xxmaj here is advise on xxunk yourself and your kids . xxmaj setting a good example , teaching them how to make proper choices , and xxunk them for a healthy life . xxmaj does n't neglect exercise . xxmaj good recipes . xxmaj does n't require xxunk fat or xxunk , just being smart . xxmaj put away your xxunk and become a xxunk in your household , here 's how . xxmaj your kids and xxunk will thank you for generations .,xxbos xxmaj another book that teaches kids that being bigger is a personal xxunk caused by personal xxunk , and too much eating . xxmaj if you just quit doing ' this ' and stop doing ' that ' you can be just like the other kids . xxmaj complete xxunk . a waste of money . xxmaj find a book that will teach your children about the value of being different , not one that tries to xxunk them into xxunk xxunk .,xxbos xxmaj xxunk is a very impressive xxunk : a quiet , xxunk cop film . xxmaj its premise is familiar : two very different xxunk working to xxunk to each other and to the many xxunk of their jobs as xxunk . xxmaj so it 's very much a character study , and the two xxunk actors -- xxmaj bill xxmaj sage and xxmaj bill xxmaj xxunk -- do an excellent job of xxunk their characters . xxmaj as the film 's energy is xxunk from their characters ' different xxunk , it would have been very easy for each of their performances to become xxunk . xxmaj they did not . xxmaj in each , you see a fully - xxunk person , including xxunk of his partner 's xxunk . xxmaj that 's good acting of good writing . i also enjoyed the matter - of - fact style of the film , which xxunk me of xxmaj xxunk xxmaj xxunk 's wonderful and under - appreciated xxmaj ruby xxmaj in xxmaj xxunk .\n",
              "y: CategoryList\n",
              "3,4,5,1,3\n",
              "Path: Data/amazon_review_full_csv;\n",
              "\n",
              "Valid: LabelList (1000 items)\n",
              "x: TextList\n",
              "xxbos i ordered the xxunk color of these xxunk as i wanted something neutral but not completely white . xxmaj the xxunk color is more of a xxunk color so i sent them back . xxmaj overall , i loved the dishes and the fact that they are made in the xxup usa and are lead - free . i will buy them again but find a color that works for me .,xxbos i currently own six of these sets in different colors . xxmaj these xxunk are heavy and well made . xxmaj worth the price . xxmaj my xxunk now looks like something out of a xxmaj xxunk xxmaj anderson movie .,xxbos i have several place settings of xxmaj xxunk xxmaj dishes . i ordered 2 more place settings recently and was dissapointed with them . xxmaj the dishes are warped and do n't stack well with my other dishes . xxmaj these dishes are xxunk xxunk . i love the idea of the xxmaj xxunk brand but these were not like my others .,xxbos i read the title wrong . i thought i was getting a setting for four . xxmaj one of the xxunk came xxunk and i made a note of it on here . i never got a response . i decided to keep it . i am not going to buy any more sets . i saw a few days ago at xxmaj xxunk , they have the same set . xxmaj it was xxunk cheaper with your xxmaj xxunk xxunk .,xxbos xxmaj this book is for any mother in the process of xxunk . xxmaj unlike one reviewer , i thought the author did an excellent job of explaining everything a mother needs to consider . xxmaj the tips were so helpful ... so many things i had n't thought of ! xxmaj it gave me insight into my children 's needs , and insight into xxunk , xxunk , and child support , xxunk an xxunk , etc . i believe i got a much better xxunk because of this book , and it gave me piece of mind to read the stories of the women it detailed . i bought several books to try to xxunk myself , but this one was the best by far . xxmaj it covers so many topics . xxmaj it should be recommended reading by xxunk , xxunk , and marriage xxunk .\n",
              "y: CategoryList\n",
              "3,5,2,2,5\n",
              "Path: Data/amazon_review_full_csv;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3952, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3952, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.4, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f3d7998fa70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('Data/amazon_review_full_csv'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: ...\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(3952, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3952, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.4, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "m4eLJKxkzjW1",
        "outputId": "150fe71a-3a23-4b9c-c78f-d5628ff0d565"
      },
      "source": [
        "learn_c.freeze_to(-2)\n",
        "learn_c.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.423040</td>\n",
              "      <td>1.484008</td>\n",
              "      <td>0.329000</td>\n",
              "      <td>02:08</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1N9D4TW6z-J-"
      },
      "source": [
        "learn_c.save('class-2nd')"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NfDnNyJF2nRd"
      },
      "source": [
        "learn_c.load('class-2nd');"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 151
        },
        "id": "xytKLkFL2pzw",
        "outputId": "6f93fbb1-6ce2-4498-ccc4-9256ffbbf240"
      },
      "source": [
        "learn_c.freeze_to(-3)\n",
        "learn_c.fit_one_cycle(1, slice(1e-2/(2.6**4),1e-2))"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.378896</td>\n",
              "      <td>1.460778</td>\n",
              "      <td>0.358000</td>\n",
              "      <td>03:15</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Fk7VNBe2uvR"
      },
      "source": [
        "learn_c.save('class-3rd')"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vw0XyRIR6F4y",
        "outputId": "40d1c21a-8192-43fa-d5d7-cb331a56c3bf"
      },
      "source": [
        "learn_c.load('class-3rd')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RNNLearner(data=TextClasDataBunch;\n",
              "\n",
              "Train: LabelList (1000 items)\n",
              "x: TextList\n",
              "xxbos xxmaj interesting kung fu xxunk xxmaj combination of xxmaj white xxmaj xxunk and xxmaj xxunk xxmaj xxunk ? xxmaj the practitioners seem to have solid xxunk and not a lot of superfluous or wasted movement . xxmaj would like to have seen more applications xxunk just a couple in the last few minutes of the video , basically an arm lock and a push . xxmaj thanks to xxmaj amazon for making these available to rent ! xxmaj enjoyable for esoteric xxunk arts video junkies like myself , gives you a chance to see what other styles you 're not likely to find at the local xxunk xxunk are doing , and to \" try before you buy \" . i 've bought several videos from the same company as this one on sale cheap , some are excellent , some are lousy , this one is in the middle . xxmaj not recommended for people wanting to learn self defense because a ) self defense applications are not xxunk out clearly , and b ) even if they were , a live teacher and a lot of realistic training is needed to make any system work in real life .,xxbos xxmaj this is a well organized book with lots of useful advice and good xxunk xxunk . i just have two complaints : 1 ) xxmaj there is an xxunk that heavy kids are heavy because they eat junk food and do n't exercise . i 'm living with a heavy kid who rarely xxunk junk food and has always xxunk a lot . xxmaj this message is frustrating , to say the least . 2 ) xxmaj the title is a problem . xxmaj my daughter is already xxunk - sensitive about her weight , were i to buy this book ( i read it at the library ) , the title itself would confirm to her that i find her \" fat . \" xxmaj in fact , i would purchase this book , were it not for the title because it is among the best of the books covering the subject , and i 've read a number of them . i appreciate the books emphasis on physical xxunk . i think a person who is xxunk fit has a better life and feels better in every way . xxmaj parents have an xxunk to xxunk such well being as far as i 'm concerned .,xxbos xxmaj life is about making choices and xxunk up to them . xxmaj too many kids in xxmaj america are fat . xxmaj this did n't used to be so . xxmaj times have changed . xxmaj here is advise on xxunk yourself and your kids . xxmaj setting a good example , teaching them how to make proper choices , and xxunk them for a healthy life . xxmaj does n't neglect exercise . xxmaj good recipes . xxmaj does n't require xxunk fat or xxunk , just being smart . xxmaj put away your xxunk and become a xxunk in your household , here 's how . xxmaj your kids and xxunk will thank you for generations .,xxbos xxmaj another book that teaches kids that being bigger is a personal xxunk caused by personal xxunk , and too much eating . xxmaj if you just quit doing ' this ' and stop doing ' that ' you can be just like the other kids . xxmaj complete xxunk . a waste of money . xxmaj find a book that will teach your children about the value of being different , not one that tries to xxunk them into xxunk xxunk .,xxbos xxmaj xxunk is a very impressive xxunk : a quiet , xxunk cop film . xxmaj its premise is familiar : two very different xxunk working to xxunk to each other and to the many xxunk of their jobs as xxunk . xxmaj so it 's very much a character study , and the two xxunk actors -- xxmaj bill xxmaj sage and xxmaj bill xxmaj xxunk -- do an excellent job of xxunk their characters . xxmaj as the film 's energy is xxunk from their characters ' different xxunk , it would have been very easy for each of their performances to become xxunk . xxmaj they did not . xxmaj in each , you see a fully - xxunk person , including xxunk of his partner 's xxunk . xxmaj that 's good acting of good writing . i also enjoyed the matter - of - fact style of the film , which xxunk me of xxmaj xxunk xxmaj xxunk 's wonderful and under - appreciated xxmaj ruby xxmaj in xxmaj xxunk .\n",
              "y: CategoryList\n",
              "3,4,5,1,3\n",
              "Path: Data/amazon_review_full_csv;\n",
              "\n",
              "Valid: LabelList (1000 items)\n",
              "x: TextList\n",
              "xxbos i ordered the xxunk color of these xxunk as i wanted something neutral but not completely white . xxmaj the xxunk color is more of a xxunk color so i sent them back . xxmaj overall , i loved the dishes and the fact that they are made in the xxup usa and are lead - free . i will buy them again but find a color that works for me .,xxbos i currently own six of these sets in different colors . xxmaj these xxunk are heavy and well made . xxmaj worth the price . xxmaj my xxunk now looks like something out of a xxmaj xxunk xxmaj anderson movie .,xxbos i have several place settings of xxmaj xxunk xxmaj dishes . i ordered 2 more place settings recently and was dissapointed with them . xxmaj the dishes are warped and do n't stack well with my other dishes . xxmaj these dishes are xxunk xxunk . i love the idea of the xxmaj xxunk brand but these were not like my others .,xxbos i read the title wrong . i thought i was getting a setting for four . xxmaj one of the xxunk came xxunk and i made a note of it on here . i never got a response . i decided to keep it . i am not going to buy any more sets . i saw a few days ago at xxmaj xxunk , they have the same set . xxmaj it was xxunk cheaper with your xxmaj xxunk xxunk .,xxbos xxmaj this book is for any mother in the process of xxunk . xxmaj unlike one reviewer , i thought the author did an excellent job of explaining everything a mother needs to consider . xxmaj the tips were so helpful ... so many things i had n't thought of ! xxmaj it gave me insight into my children 's needs , and insight into xxunk , xxunk , and child support , xxunk an xxunk , etc . i believe i got a much better xxunk because of this book , and it gave me piece of mind to read the stories of the women it detailed . i bought several books to try to xxunk myself , but this one was the best by far . xxmaj it covers so many topics . xxmaj it should be recommended reading by xxunk , xxunk , and marriage xxunk .\n",
              "y: CategoryList\n",
              "3,5,2,2,5\n",
              "Path: Data/amazon_review_full_csv;\n",
              "\n",
              "Test: None, model=SequentialRNN(\n",
              "  (0): MultiBatchEncoder(\n",
              "    (module): AWD_LSTM(\n",
              "      (encoder): Embedding(3952, 400, padding_idx=1)\n",
              "      (encoder_dp): EmbeddingDropout(\n",
              "        (emb): Embedding(3952, 400, padding_idx=1)\n",
              "      )\n",
              "      (rnns): ModuleList(\n",
              "        (0): WeightDropout(\n",
              "          (module): LSTM(400, 1152, batch_first=True)\n",
              "        )\n",
              "        (1): WeightDropout(\n",
              "          (module): LSTM(1152, 1152, batch_first=True)\n",
              "        )\n",
              "        (2): WeightDropout(\n",
              "          (module): LSTM(1152, 400, batch_first=True)\n",
              "        )\n",
              "      )\n",
              "      (input_dp): RNNDropout()\n",
              "      (hidden_dps): ModuleList(\n",
              "        (0): RNNDropout()\n",
              "        (1): RNNDropout()\n",
              "        (2): RNNDropout()\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (1): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.4, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              "), opt_func=functools.partial(<class 'torch.optim.adam.Adam'>, betas=(0.9, 0.99)), loss_func=FlattenedLoss of CrossEntropyLoss(), metrics=[<function accuracy at 0x7f3d7998fa70>], true_wd=True, bn_wd=True, wd=0.01, train_bn=True, path=PosixPath('Data/amazon_review_full_csv'), model_dir='models', callback_fns=[functools.partial(<class 'fastai.basic_train.Recorder'>, add_time=True, silent=False)], callbacks=[RNNTrainer\n",
              "learn: ...\n",
              "alpha: 2.0\n",
              "beta: 1.0], layer_groups=[Sequential(\n",
              "  (0): Embedding(3952, 400, padding_idx=1)\n",
              "  (1): EmbeddingDropout(\n",
              "    (emb): Embedding(3952, 400, padding_idx=1)\n",
              "  )\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(400, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 1152, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): WeightDropout(\n",
              "    (module): LSTM(1152, 400, batch_first=True)\n",
              "  )\n",
              "  (1): RNNDropout()\n",
              "), Sequential(\n",
              "  (0): PoolingLinearClassifier(\n",
              "    (layers): Sequential(\n",
              "      (0): BatchNorm1d(1200, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (1): Dropout(p=0.4, inplace=False)\n",
              "      (2): Linear(in_features=1200, out_features=50, bias=True)\n",
              "      (3): ReLU(inplace=True)\n",
              "      (4): BatchNorm1d(50, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
              "      (5): Dropout(p=0.1, inplace=False)\n",
              "      (6): Linear(in_features=50, out_features=5, bias=True)\n",
              "    )\n",
              "  )\n",
              ")], add_time=True, silent=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 479
        },
        "id": "OsgpS5l-6INt",
        "outputId": "45f6fff1-c1cd-493f-dd09-ffb6ae0866d5"
      },
      "source": [
        "learn_c.unfreeze()\n",
        "learn_c.fit_one_cycle(5, slice(1e-3/(2.6**4), 1e-3))"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>epoch</th>\n",
              "      <th>train_loss</th>\n",
              "      <th>valid_loss</th>\n",
              "      <th>accuracy</th>\n",
              "      <th>time</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>1.308628</td>\n",
              "      <td>1.450467</td>\n",
              "      <td>0.357000</td>\n",
              "      <td>04:10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.307903</td>\n",
              "      <td>1.436624</td>\n",
              "      <td>0.369000</td>\n",
              "      <td>04:17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>1.279905</td>\n",
              "      <td>1.430527</td>\n",
              "      <td>0.373000</td>\n",
              "      <td>03:56</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>1.272667</td>\n",
              "      <td>1.431498</td>\n",
              "      <td>0.371000</td>\n",
              "      <td>04:07</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>1.267079</td>\n",
              "      <td>1.420936</td>\n",
              "      <td>0.369000</td>\n",
              "      <td>04:13</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "/usr/local/lib/python3.7/dist-packages/numpy/core/_asarray.py:83: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n",
            "  return array(a, dtype, copy=False, order=order)\n",
            "<string>:6: VisibleDeprecationWarning: Creating an ndarray from ragged nested sequences (which is a list-or-tuple of lists-or-tuples-or ndarrays with different lengths or shapes) is deprecated. If you meant to do this, you must specify 'dtype=object' when creating the ndarray\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9Pd7tziK6Lr0"
      },
      "source": [
        "learn_c.save('classification')"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nacab6Pw_Gtq",
        "outputId": "aba485a9-b704-4b07-e587-ed76f92198ae"
      },
      "source": [
        "learn_c.predict(\"I really loved that shirt, it fit perfectly.\")"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(4),\n",
              " tensor(4),\n",
              " tensor([0.0024, 0.0142, 0.0241, 0.0897, 0.8696]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qjuZhx8d_LwV",
        "outputId": "b3df9640-75ed-43de-c202-b4e5789dba65"
      },
      "source": [
        "learn_c.predict(\"I didn't really like the table, it was ugly.\")"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(Category tensor(1),\n",
              " tensor(1),\n",
              " tensor([0.1804, 0.4248, 0.2756, 0.0516, 0.0675]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    }
  ]
}